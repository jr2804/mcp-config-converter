# LLM Provider API Keys Configuration
#
# This file contains environment variable names for all supported LLM providers.
# Copy this file to .env and fill in your actual API keys.
#
# NOTE: Never commit your actual .env file with real API keys!
#
# With the unified LiteLLM implementation, all providers are now supported through
# a single interface. Simply set the appropriate API key for your chosen provider.

# MCP Config Converter CLI Configuration
# Generic configuration options that apply to the CLI tool
# MCP_CONFIG_CONF_LLM_BASE_URL=your_custom_base_url
# MCP_CONFIG_CONF_LLM_PROVIDER_TYPE=litellm
# MCP_CONFIG_CONF_LLM_MODEL=gpt-4
# MCP_CONFIG_CONF_API_KEY=your_generic_api_key
# MCP_CONFIG_CONF_PREFERRED_PROVIDER=litellm

# ===== LiteLLM Supported Provider API Keys =====
# Set the API key for the provider you want to use with LiteLLM

# OpenAI API Key (for GPT models)
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google API Keys (for Gemini models)
# GOOGLE_API_KEY=your_google_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
# GOOGLE_GENERATIVE_AI_API_KEY=your_google_generative_ai_api_key_here

# Mistral API Key
# MISTRAL_API_KEY=your_mistral_api_key_here

# DeepSeek API Key
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenRouter API Key
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# Perplexity API Key
# PERPLEXITY_API_KEY=your_perplexity_api_key_here

# SambaNova API Key
# SAMBANOVA_API_KEY=your_sambanova_api_key_here

# ZAI API Key
# ZAI_API_KEY=your_zai_api_key_here

# Ollama - typically doesn't require an API key for local instances
# OLLAMA_BASE_URL=http://localhost:11434

# ===== Legacy Provider-Specific API Keys =====
# These are maintained for backward compatibility with legacy provider implementations
# You should use the LiteLLM provider instead (see above)