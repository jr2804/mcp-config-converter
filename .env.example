# LLM Provider API Keys Configuration
#
# This file contains example environment variable names for all supported LLM providers.
# Copy this file to .env and fill in your actual API keys.
#
# NOTE: Never commit your actual .env file with real API keys!

# MCP Config Converter CLI Configuration
# Generic configuration options that apply to the CLI tool
# MCP_CONFIG_CONF_LLM_BASE_URL=your_custom_base_url
# MCP_CONFIG_CONF_LLM_PROVIDER_TYPE=openai
# MCP_CONFIG_CONF_LLM_MODEL=gpt-4
# MCP_CONFIG_CONF_API_KEY=your_generic_api_key
# MCP_CONFIG_CONF_PREFERRED_PROVIDER=auto

# Provider-specific API Keys (used if MCP_CONFIG_CONF_API_KEY is not set)
# OpenAI API Key
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (Claude) API Key
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API Key
# GOOGLE_API_KEY=your_google_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here
# GOOGLE_GENERATIVE_AI_API_KEY=your_google_generative_ai_api_key_here

# Mistral API Key
# MISTRAL_API_KEY=your_mistral_api_key_here

# DeepSeek API Key
# DEEPSEEK_API_KEY=your_deepseek_api_key_here

# OpenRouter API Key
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# Perplexity API Key
# PERPLEXITY_API_KEY=your_perplexity_api_key_here

# SambaNova API Key
# SAMBANOVA_API_KEY=your_sambanova_api_key_here

# ZAI API Key
# ZAI_API_KEY=your_zai_api_key_here

# Ollama - typically doesn't require an API key for local instances
# OLLAMA_BASE_URL=http://localhost:11434