{"id":"mcp-ps3","title":"Fix LiteLLMClient.get_available_models() to use get_valid_models()","description":"## Context\n\nThe `LiteLLMClient.get_available_models()` method in `mcp_config_converter/llm/client.py` (lines 180-198) currently uses `model_cost` dictionary to retrieve available models. This is incorrect because model_cost is a pricing/metadata dictionary, not a comprehensive list of available models.\n\n## Problem\n\nCurrent implementation issues:\n\n1. Uses `model_cost` dictionary which only contains pricing information\n2. Returns incorrect/filtered model lists for providers\n3. Does not leverage LiteLLM's built-in `get_valid_models()` helper function\n\nAccording to LiteLLM documentation (https://docs.litellm.ai/docs/set_keys#get_valid_models), correct approach is to use `get_valid_models()` helper function.\n\n## Implementation Details\n\nFrom LiteLLM docs:\n\n```python\nfrom litellm import get_valid_models\n\n# Basic usage - reads .env and returns supported models\nvalid_models = get_valid_models()\n\n# Query provider endpoints for valid models (more accurate but slower)\nvalid_models = get_valid_models(check_provider_endpoint=True)\n\n# Check specific provider only\nvalid_models = get_valid_models(\n    check_provider_endpoint=True, \n    custom_llm_provider=\"openai\"\n)\n```\n\n## Requirements\n\n1. Replace `get_available_models()` implementation:\n   - Import `get_valid_models` from `litellm`\n   - Call `get_valid_models()` instead of accessing `model_cost`\n   - Filter results by provider if `self.provider` is set\n\n2. Consider using `check_provider_endpoint=True`:\n   - More accurate model lists by querying provider endpoints\n   - Currently supported providers: OpenAI, Fireworks AI, LiteLLM Proxy, Gemini, XAI, Anthropic\n   - Trade-off: slower but more accurate\n\n3. Handle errors gracefully:\n   - `get_valid_models()` can raise exceptions\n   - Log errors and return empty list on failure\n   - Maintain current error handling pattern\n\n## Files to Modify\n\n- `mcp_config_converter/llm/client.py` - Replace `get_available_models()` method implementation\n\n## Testing Considerations\n\n- Test with various providers (openai, anthropic, gemini, ollama, etc.)\n- Verify model filtering by provider works correctly\n- Test with and without `check_provider_endpoint=True`\n- Ensure error handling works when provider endpoints are unavailable\n- Test with environment variables set for different providers","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-04T03:44:21.1073251+01:00","created_by":"Jan Reimes","updated_at":"2026-01-04T04:16:27.7405444+01:00","closed_at":"2026-01-04T04:16:27.7405444+01:00","close_reason":"Closed"}
